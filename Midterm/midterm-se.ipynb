{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adfa8fa-ca7b-4ad1-a493-82724403e3b3",
   "metadata": {},
   "source": [
    "# Midterm | R Lab for Applied Data Science\n",
    "\n",
    "## General Instructions\n",
    "\n",
    "*   This is an open-book, open-notes assignment. You are encouraged to use your course materials, online resources, and R documentation.\n",
    "*   Show all your R code and output clearly within your Jupyter Notebook. Use markdown cells to provide explanations and interpretations of your code and results.\n",
    "*   For each task, clearly state the task number and provide a concise answer or interpretation. I'll have code blocks below each task.\n",
    "*   Justify your choices of data manipulation techniques, visualizations, and analytical approaches. There is often more than one \"correct\" way to approach a data science problem.\n",
    "*   Pay attention to code clarity, readability, and proper commenting.\n",
    "*   The assignment is designed to assess your understanding and application of the concepts and techniques covered in Modules 1-6.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "We'll be using several datatsets for this midterm. Be sure to download all the datasets from the Canvas assignment before you begin. The data will be in a zip folder called `midterm-data.zip`. The datasets we'll be using are:\n",
    "\n",
    "-  `penguins.rds` (from the `palmerpenguins` package)\n",
    "-  `diamonds.rds` (from the `ggplot2` package)\n",
    "-  `sleep.rds` (from the `VIM` package)\n",
    "-  `sms-spam.rds` (from [kaggle](https://www.kaggle.com/datasets/thedevastator/sms-spam-collection-a-more-diverse-dataset))\n",
    "\n",
    "There are a total of **13 tasks**. Be sure to read through and answer every step for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0c2eb-bca5-46b6-a799-c9a39d27e909",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "### Task 1: Exploring the Penguins Dataset\n",
    "\n",
    "1. Load the `penguins.rds` dataset.\n",
    "2. Examine the structure of the penguins dataset. What are the different variable types present (e.g., numeric, factor)? List at least three variables of different types and identify their types.\n",
    "3. Calculate and present the mean and standard deviation of the `body_mass_g` (body mass in grams) for each penguin species. Briefly interpret these statistics - which species tends to be heavier on average?\n",
    "4. Create a vector containing the unique island names where penguins were observed. How many unique islands are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc19bac-b67e-4d67-abd7-1f651eeff8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7d39c-a9ec-4630-9a86-faf93ef266d5",
   "metadata": {},
   "source": [
    "### Task 2: Conditional Data Analysis\n",
    "\n",
    "1. Using the penguins dataset, identify penguins that are of the `Gentoo` species and have a flipper length greater than 200 mm.\n",
    "2. For these identified penguins, calculate the minimum, 1st quartile, median, mean, 3rd quartile and max (`summary()`) bill depth (`bill_depth_mm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541b612-45b2-4062-ac20-f3b867045f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68649f3-21f0-4f08-9525-2de1c2c3dd77",
   "metadata": {},
   "source": [
    "### Task 3: Diamonds Data Exploration and Filtering\n",
    "\n",
    "1. Load the `diamonds.rds` dataset.\n",
    "2. Filter the diamonds dataset to include only diamonds with a `cut` quality of `Ideal`.\n",
    "3. Produce a scatterplot showing the `caret` vs the `price`. Color of the points given the `color` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9579d9-ed6c-482b-ba05-7c170ab243fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a96c2-27ec-4aa1-8e67-a2150078e25e",
   "metadata": {},
   "source": [
    "### Task 4: Data Transformation and Summarization\n",
    "\n",
    "1. Using the original diamonds dataset, create a new variable called `volume` which represents the volume of the diamond, calculated as `x` * `y` * `z`.\n",
    "2. Group the diamonds data by `cut` quality.\n",
    "3. For each cut quality, calculate the median `price` and the median `volume`.\n",
    "4. Present the results in ascending order of median price. Which diamond cut quality has the lowest median price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42994b-ad0e-45fe-a073-c46a3bcfe6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966aab4-7c1d-4d01-93f0-31eb23f70e95",
   "metadata": {},
   "source": [
    "### Task 5: Creating Categories and Summarizing Price per Carat\n",
    "\n",
    "1. Using the diamonds dataset, create a new categorical variable called `carat_category` based on the `carat` variable. Define the categories as follows:\n",
    "    1. \"Small\": diamonds with carat less than 0.5\n",
    "    2. \"Medium\": diamonds with carat between 0.5 and 1 (inclusive of 0.5, exclusive of 1)\n",
    "    3. \"Large\": diamonds with carat 1 or greater\n",
    "2. Group the diamonds data by this newly created `carat_category`.\n",
    "3. Plot the distribution of price per carat category.\n",
    "4. Within each carat_category, calculate the average price per carat (i.e., price / carat).\n",
    "5. Present the results showing the average price per carat for each category, in descending order of average price per carat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9b264-e410-49b5-ba55-c828d4a9343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14485a70-1fc4-4656-9168-76a563617a93",
   "metadata": {},
   "source": [
    "### Task 6: Data Joining\n",
    "\n",
    "Imagine you had two datasets related to diamonds: one with diamond characteristics (diamonds dataset as we have) and another hypothetical dataset called `diamond_ratings` that contains information about diamond certifications and ratings, linked by a common diamond ID.\n",
    "\n",
    "1. Explain conceptually how you would combine these two datasets based on a common ID. Describe which type of join you would use if you wanted to keep all rows from the diamonds dataset, even if some diamonds don't have a matching rating in `diamond_ratings`.\n",
    "2. Provide example R code demonstrating the syntax of how you would perform this join, assuming both datasets exist and have a common ID column named 'diamond_id'. (You don't need to actually run code on hypothetical data, just show the syntax.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7dd66-3a01-4a2a-8bb1-c958d3cb7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c82f4-caa8-40f8-825e-ac82627a542f",
   "metadata": {},
   "source": [
    "### Task 7: A Simple model of Diamond Prices\n",
    "\n",
    "1. Build a simple linear model of `price` as a function of any one or more of the other variables. Apply any transformations as you see fit.\n",
    "2. Produce an \"actual vs prediction\" plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401fbd6-7bff-494c-ae02-e1d204eed490",
   "metadata": {},
   "source": [
    "### Task 8: Acquiring Financial Data for Multiple Stocks with `tidyquant`\n",
    "\n",
    "1. Using the `tidyquant` package, retrieve the daily stock price data for Microsoft Corp. (MSFT) and Alphabet Inc. (GOOG) from January 1, 2021, to December 31, 2021.\n",
    "2. For each stock, calculate the daily percentage change in the 'adjusted' closing price during this period.\n",
    "3. Create a plot showing the distribution of the daily percentage change for each stock.\n",
    "4. For each stock, calculate the cumulative product of daily percentage change (don't forget to add 1 first, then subtract at the end).\n",
    "5. Create a single time series plot showing the cummulative percent change for both MSFT and GOOG on the same plot over the specified period, using different colors for each stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0359b-af77-4acd-93f6-5024ffc6966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a72b52-4bb1-4722-9359-af7171de7085",
   "metadata": {},
   "source": [
    "### Task 9: Interactive charts\n",
    "\n",
    "1. Turn the plots you produced in task 8 into interactive plots with plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa97cf-dc8c-4b9e-b951-a84f1e8993d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80104ef8-6b12-475b-8ced-d3ec0327fda1",
   "metadata": {},
   "source": [
    "### Task 10: Identifying and Visualizing Missing Data in Sleep Dataset\n",
    "\n",
    "1. Load the `sleep.rds` dataset from the `VIM` package (`library(VIM); data(sleep)`).\n",
    "2. Create a visualization using either the `visdat` or `naniar` package to visualize the pattern of missing data in the `sleep` dataset. Which pair of variables have the most concurrent missing observations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d309b-b4f7-468c-97f5-bafa788f813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776209d1-06b9-4e17-9a06-96bc1ed50e80",
   "metadata": {},
   "source": [
    "### Task 11: Imputation of Missing Values in Sleep Dataset and Comparison \n",
    "\n",
    "Focus on the `NonD` column in the `sleep` dataset, which has missing values. Implement two different methods to impute these missing values:\n",
    "1. **Method 1: Median Imputation:** Replace missing `NonD` values with the median of the available `NonD` values.\n",
    "2. **Method 2: Regression Imputation (Simple):**  Use a linear regression model to predict `NonD`. Choose one or more relevant predictors, but keep in mind you want to fill in all the NAs.\n",
    "3. After performing both imputations, produce a plot that shows the distribution of `NonD`, the filled values using the median, and the filled values using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c21b0f-48c4-47bf-b137-eeeb22ad705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4d26b-614f-41d8-b3c8-88e6b4747b31",
   "metadata": {},
   "source": [
    "### Task 12: Building a More Complex Model of Diamond Prices\n",
    "\n",
    "Begin by running the code below. We'll use a subset of the diamonds dataset so you don't have to wait so long for the model to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65f762-871b-4cc1-a9f7-c25e29a4f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2025)\n",
    "\n",
    "tb_diamonds = readRDS(\"midterm-data/diamonds.rds\") # change this path if you need to\n",
    "\n",
    "tb_diamonds_subset = tb_diamonds %>% \n",
    "    slice_sample(prop = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea787936-17db-4886-bfeb-aaef32c7d2b4",
   "metadata": {},
   "source": [
    "Using `tb_diamonds_subset`, you want to predict `price` using other diamond characteristics. \n",
    "\n",
    "1. Begin by engineering some features (consider taking the logarithm of `price`).\n",
    "2. Next do 80/20 split of the data (80% training, 20% testing).\n",
    "3. Using the 5-fold CV of the training set, apply either a **wrapper method** (e.g. random forest) or a **embedded method** (e.g. LASSO) to select features.\n",
    "4. With the selected features, fully train the model on the training set (if not done during the 5-fold CV training), then make predictions on the test set. Calculate the NRMSE.\n",
    "5. Using the your model formulation in task 7, train the linear model on the 80% data, then test it on the 20%. Calculate the NRMSE. How do your models compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790f686-3bdf-4ef3-b45b-b3a28812f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8334776-8e6c-4b74-804f-38735946afca",
   "metadata": {},
   "source": [
    "### Task 13: Text Tokenization and Visualization of SMS Spam Data\n",
    "\n",
    "**There is some coarse language in this dataset, so apologies beforehand!**\n",
    "\n",
    "1. Load the `sms-spam.rds` dataset.\n",
    "2. Tokenize the texts (`sms`) column by word. \n",
    "3. Remove stop words, and add a column for the sentiment of each word. Add a numeric value for the sentiment (e.g. -1 for negative and 1 for positive).\n",
    "4. Perform a student's t-Test (`t.test()`) on a vector containing the sentiment scores of no-spam text messages (`label == 0`) and spam text messages (`label == 1`). Is there a \"statistically significant\" (p-value < 0.05) difference between the mean sentiments? Interpret the mean sentiment of the spam messages.\n",
    "5. Produce a wordcloud using the positive words in regular text messages and the positive words in the spam text messages. Do the same for the negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e8f7a-8083-43a5-b773-fb146e899511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
